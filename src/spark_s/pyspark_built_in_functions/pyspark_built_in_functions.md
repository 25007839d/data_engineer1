# 1 pyspark_built_in_functions
when() → Conditional (if-else)

expr() → SQL-like expressions in DataFrame API

lit() → Add literal values

split() → Split string into array

concat_ws() → Concatenate with separator

substring() → Extract substring

translate() → Replace characters

regexp_replace() → Regex-based replace

overlay() → Replace substring at position

to_timestamp() / to_date() → Convert string to timestamp/date

date_format() → Format date

datediff() → Difference between dates

months_between() → Month difference between dates

explode() → Flatten arrays

array_contains() → Check value in array

array() → Create array

collect_list() / collect_set() → Aggregations into list/set

create_map() → Create map column

map_keys() / map_values() → Extract keys/values from map

struct() → Combine multiple cols into struct

countDistinct() → Count unique values

sum(), avg() → Aggregations

row_number(), rank(), dense_rank(), percent_rank() → Window functions

typedLit() → Create typed literal column

from_json() / to_json() → Parse / convert JSON

json_tuple() → Extract JSON fields

get_json_object() → Extract JSON path

schema_of_json() → Infer schema from JSON

